# MySQL实战—学习笔记

## 执行流程

- 执行流程
  - MySQL分为两层：Server层和存储引擎层。
  - Server层：负责处理客户端的请求并与存储引擎层交互
    - 连接器：管理连接与权限验证，可以通过`show processlist`查看。连接分为两种，短连接(每次只需完就断开)和长连接(持续请求，使用建立的连接)，通常建议使用长连接，但长连接会占用大量内存(执行SQL时的临时内存由连接对象管理)，内存占用很大时，MySQL会异常重启(被系统强杀)，因此建议在执行占用内存大的操作后断开连接或执行`mysql_reset_connection`重新初始化连接资源(该操作不需要重连)。
    - 查询缓存：如果该语句之前执行过，MySQL会以`key=语句，value=结果`的形式缓存，若语句在缓存中直接返回结果，若不在则执行后续步骤，将结果缓存。MySQL8.0已经取消掉缓存，因为缓存失效十分频繁(更新，则缓存失效)。8.0之前的版本可以设置参数`query_cache_type=DEMAND`默认不查询缓存或显式指定查询缓存`SELECT SQL_CACHE * FROM T;`。
    - 分析器：进行词法和语法分析，判断语句是否有误。
    - 优化器：确定语句的执行方案。
    - 执行器：判断执行权限，根据执行方案执行。
  - 存储引擎层：负责数据的存取
- MySQL资料收集
  - 用好debug模式
  - 《高性能MySQL》

## 日志系统：一条SQL更新语句是如何执行的？

- 更新流程：更新流程在执行时会涉及两个日志模块：重做日志(redo log)和归档日志(binlog)。
- 重做日志：重做日志是InnoDB数据引擎特有的日志。其目的是为了避免每次更新都写入磁盘带来的高消耗。MySQL会现将更新操作记录在重做日志中，然后更新内存中的数据，完成更新操作(WAL)。当系统空闲时，再将内存中的数据写入磁盘，通过该方法，InnoDB保证了数据库发送异常重启，也不会丢失数据(crash-safe)。重做日志是一个循环列表，如果写满，则必须将数据写入磁盘，擦除掉这部分日志。重做日志记录的是物理日志，即在某个数据页上做了什么修改。可以设置参数`innodb_flush_log_at_trx_commit=1`，确保每次事务的重做日志持久化到磁盘。
- 归档日志：归档日志是Server层的日志，记录更新语句的原始逻辑。归档日志是追加写的，写到一定大小后，会切换到新的日志。可以设置参数`sync_log=1`，确保每次事务的归档日志持久化到磁盘。
- 更新语句流程
- 数据恢复流程：根据对应时间点的全量备份恢复到临时库，然后将该时间点后的归档日志进行重放。
- 日志两段提交：保证两份日志的逻辑一致。
  - 重做日志为prepare状态时，在写binlog时crash
    - 重启恢复：没有commit，也没有binlog，回滚
  - 写完binlog后，出现crash
    - 重启恢复：已经写入了binlog，则自动commit

## 事务隔离

事务用于保证一组数据库操作要么全部完成，要么全部失败。MySQL的事务由引擎层实现，InnoDB支持事务，而MyISAM不支持事务。

- 事务的ACID特性
  - 原子性(Atomicity)：事务中所有的操作要么全部成功，要么全部失败。
  - 一致性(Consistency)：事务执行前和执行后状态一致。
  - 隔离性(Isolation)：事务之间的操作是互不影响。
  - 持久性(Durability)：事务提交后，对数据的修改是永久。
- 隔离级别：隔离越好，效率越低，配置方式`transaction-isolation`，其实现为视图，具体数据以视图为准。
  - 读未提交：事务未提交前，其变更能被其他事务读取到。没有创建视图，直接返回最新数据。
  - 读提交：事务提交后，其变更才能被其他事务读取到。每个SQL语句启动时创建视图。
  - 可重复读：事务执行过程中看到的数据和事务执行前看到的数据一致。事务启动时创建视图。
  - 串行化：添加读写锁，后续事务必须等前一个事务完成才能执行。
- 事务隔离的具体实现：事务隔离是基于回滚日志的，要想恢复数据，必须依次回滚。当系统中没有比该日志更早的视图时，即可删除掉该日志。
- 长事务：长事务意味着系统中会存在很老的事务视图，由于这些事务随时都可能访问数据库中的数据，因此事务提交之前，必须保留回滚日志，会占用大量存储空间。
- 事务启动
  - 显式启动，begin或start transaction。提交语句commit，回滚语句rollback。
  - 通过`set autocommit=0`关闭自动提交事务，则意味着执行select语句后，事务则启动，不会自动提交，会留存到执行commit、rollback或断开连接。
  - 针对频繁使用事务的业务，可以通过`commit work and chain`语法，提交事务后自动启动下一个事务，节省再次执行begin的开销。
  - 查询表中的长事务：`select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)>60);`
  - 综上：使用`set autocommit=1`，然后显式启动事务。
- 如何避免长事务对业务的影响？
  - 应用开发端
    - 确认是否使用了`set autocommit=0`：可以通过general_log搭配业务逻辑判断。
    - 确认是否有不必要的只读事务。
    - 连接数据库时，通过`SET MAX_EXECUTION_TIME`控制每条语句最大执行时间。
  - 数据库端
    - 监控`information_schema.innodb_trx`表，设置长事务阀值，超过即报警。
    - pt-kill工具
    - 业务功能测试阶段输出所有的general_log，提前分析。
    - 版本大于5.6，将`innodb_undo_tablespaces`设置大点。

## 索引

索引的目的是提交查询效率。

- 常见索引模型
  - 哈希表：哈希表是数组+链表结构，通过哈希函数计算Key在数组中的位置，然后将数据存储在目标位置上，如果出现冲突，则建立链表，用于存储冲突值。由于其不是有序排布的，因此只适合做等值查询，不适合区间查询，相关引擎：Memcached。
  - 有序数组：将数据排序放在数组收，查找时通过二分法查找($O(log(N))$)。有序数组只适合等值查询和范围查询的静态存储索引(插入、删除数据成本太高)
  - 搜索树：建立二叉搜索树，其特点是左<父<右，因此从左到右也是有序的，查找时间复杂度为$O(log(N))$，更新时间复杂度也是$O(log(N))$。搜索树通常采用的是N叉树，因为索引还需要存储在磁盘中，树高决定了其访问磁盘次数，为了尽可能少访问磁盘。
  - 数据库底层存储的核心是数据模型，因此分析数据库适用场景应该关注数据模型。
- InnoDB的索引模型：InnoDB中，表是根据主键顺序以索引形式存放(索引组织表)，InnoDB中采用B+树索引模型，所以数据是存储在B+树中，每个索引对应一个B+树。索引类型分为主键索引和非主键索引，主键索引中叶子节点存储整行数据，因此主键索引也被称作为聚簇索引。非主键索引的叶子节点内容为主键值，因此费主键索引又被称作为二级索引。基于非主键索引的查询有查询两颗索引树(回表，回到主键索引树搜索)，因此尽量使用主键索引。

- 索引维护：B+树为了维护索引有序性，插入新值时可能会出现页分裂，降低性能和空间利用率，如果两个相邻页删除了数据后，利用率低，会出现数据页合并现象。
- 自增主键：每次插入一条新纪录时，都是追加操作，因此不会出现页分离现象，如果采用逻辑字段做主键，维护数据有序性成本高。从空间上，主键长度越小，二级索引所占中间越小。因此从性能和空间上，自增主键更适合。
- 业务字段做主键场景：KV场景(只有一个索引且索引值唯一)，从性能上，主键索引更好。
- 索引重建：因为删除或页分离，导致数据页空洞，通过索引重建，重新将数据按序插入，提高页面利用率。
  - 二级索引：二级索引更适合删除索引再重建。
    - `alter table T drop index x;`
    - `alter table T add index x;`
  - 主键索引：主键索引不论删除还是创建，都会导致整个表重建，因此推荐使用`alter table T engine=InnoDB;`
    - `alter table T drop primary key;`
    - `alter table T add primary key(x);`
- N叉树的N值可以通过page大小来间接控制，调整key的大小。
- 覆盖索引：通过二级索引查询时，需要回表。如果二级索引中已经存在了需要查询的数据，则可以检索一次查询，因此覆盖索引可以检索树的搜索次数。最简单的索引覆盖是建立冗余的联合索引，联合索引的维护需要代价，因此需要衡量代价。
- 最左前缀原则：B+搜索树中，索引项是按索引中定义的字段出现的顺序排序，因此可以通过前缀定位大概范围。因此核心是如何调整字段顺序。如果既有联合查询，又有基于a、b的各自查询，如果查询条件中只有b的语句，则无法使用(a,b)的索引，只能维护一个(a,b)和(b)的索引，这是需要从空间考虑，a，b哪个所占空间小。
- 索引下推(5.6支持)：先根据二级索引中的数据过滤出符合条件的记录，然后回表。
- 主键设计考虑
  - 性能
  - 空间

## 锁

- 全局锁：全局锁是对整个数据库进行加锁，加锁后，整个数据库只读(flush tables with read lock)，通常用于一致性备份，如果在主库，则会导致备份过程中，业务基本不可用，如果在从库备份，会导致主从延迟(主库同步的binlog不能被执行)。主要解决跨表业务中，备份后表的数据不一致。在支持事务的数据引擎中，还可以使用可重复读级别事务，进行备份`mysqldump -single-transaction`。`set gloabl readonly=true`不可用，因为readonly会用于逻辑判断，如主从库，影响面过大；第二异常处理机制不同，全局锁在客户端异常断开后会自动释放，而readonly不会。
- 表级锁：
  - 表锁：`lock tables  ... read/write`，在客户端断开后，释放，不仅仅限制其他线程，也会限制本线程，使用`unlock table`主动释放锁。
  - 元数据锁(Metadata lock)：访问表时，自动添加，用于确保读写的正确性。对表增删改查添加MDL读锁，修改表结构添加MDL写锁。读锁之间不互斥，读写锁之间互斥，确保表结构安全。添加、修改字段或添加索引，会扫描全表数据，因此操作时要小心。在为表添加字段是要小心，读写锁之间互斥，事务中的MDL锁时整个事务提交后才会释放，如果出现锁互斥阻塞会话，拥有重试机制的客户端很快就会将数据库的会话用完。
    - 如何安全的添加字段？核心问题是解决长事务，如果有长事务，则暂停DDL或杀长事务，但是热点表会被频繁访问，因此kill不一定有用。最佳机制是alter table 中设定等待时间，能拿到MDL写锁，则执行，不行则放弃。`alter TABLE 表名 WAIT n add column;`
  - 表锁一般用于引擎不支持行锁的情况，如果程序中存在`lock tables`则需要排查，如果已经升级，通常可以通过将其变更为`begin`和`commit`
- 行级锁：行锁由引擎层自己实现，如果不支持行锁则只能使用表锁，因此同一张表同一时刻只能有一个更新。行锁在语句执行时才需要加上，但只有等事务结束后，才能释放。因此如果事务要锁定多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放(二阶段锁)。
  - 死锁和死锁检测：当线程之间互相等待释放资源时，会进入无限等待的状态。针对死锁有两种解决方案：
    - 等待超时：通过innodb_lock_wait_timeout设置超时时间。默认时间为50s，但时间过长，难以等待，如果设置过短，可能会误杀锁等待的会话。
    - 死锁检测，当有死锁后，主动回滚死锁链条中一个事务：通过`innodb_deadlock_detect=on`设置。但是主动死锁也需要开销，当事务被锁后，要去检查其依赖的线程是否被锁，每个线程的检查时间复杂度为$O(n)$，因此n个线程，其耗时$O(n^2)$，会消耗大量CPU资源，导致事务执行速度慢。
    - 如何解决热点行更新导致的性能问题？
      - 确保不会出现死锁情况下，把死锁检查关闭，一旦出现死锁，会导致大量超时。
      - 控制并发度，在数据库服务端控制，通过中间件或修改源码。
      - 将一条记录拆分为逻辑上的多条，减少锁冲突。
