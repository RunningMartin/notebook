# MySQL学习笔记

# 事务隔离

事务要求一组数据库操作，要么全部成功，要么全部失败。MySQL中，事务支持由引擎层实现，MyISAM不支持事务，InnoDB支持事务。

事务具备四个特性：

- 原子性(Atomicity)：原子性要求一组操作要么都执行成功，要么都执行失败。原子性是一致性的必要条件。
- 持久性(Durability)：事务完成后，事务对数据库所做的修改将持久的保存在数据库中，不会被回滚。
- 一致性(Consistency)：一致性确保事务提交成功或回滚后，数据库的完整性不被破坏。
- 隔离性(Isolation)：隔离性确保事务的执行互不干扰。

当数据库中有多个事务同时执行时，可能出现：

- 脏读：读取到别人的未提交的数据。
- 不可重复读：事务执行过程中，前后两次读取到的数据不一致。不可重复读的原因是读取到了其他事务的提交。
- 幻读：一个事务前后读取两次，得到的实录条数不一致。
- 第一类更新丢失：两个事务同时更新，第一个事务提交成功，第二个事务回滚，导致第一个事务更新内容回滚丢失。
- 第二类更新丢失：两个事务同时更新，第二个事务覆盖第一个事务更新。

为了解决这些问题，需要采用不同的隔离级别：

- 读未提交(`Read Uncommitted`)：事务能读取到其他事务未提交的修改。
- 读提交(`Read Committed`)：事务只有提交后，修改才能被其他事务看到。
- 可重复读(`Repeatable Read`)：事务执行过程中看到的数据与启动时看到的数据一致。
- 串行化(`Serializable`)：事务读写时都会加锁，当出现冲突时，后访问的事务必须等前一个事务完成。

实际上，数据库在创建一个视图，不同隔离级别的视图创建事件不同，因此访问时读取的数据也不同：

- 读未提交：无视图，直接返回记录最新值。
- 读提交：视图只在执行SQL语句时才创建。
- 可重复读：视图在启动事务时创建。
- 串行化：采用锁来避免并行访问，只针对读写、写写操作，读读操作不会限制。

不同的数据库默认隔离级别不同，Oracle默认隔离级别为读提交，从Oracle迁移到MySQL时，需要修改MySQL的隔离级别。`show variables like 'transaction-isolation';`查看隔离级别。修改方法有：

- `set [ global | session ] transaction isolation level Read uncommitted | Read committed | Repeatable | Serializable;`。
- `my.inf`配置文件：`transaction-isolation = {READ-UNCOMMITTED | READ-COMMITTED | REPEATABLE-READ | SERIALIZABLE}`。
- 命令行参数：`--transaction-isolation`

## 事务隔离的实现

MySQL中，每条记录更新时都会记录一条回滚记录，记录上的最新值，能通过回滚操作，得到前一个状态的值。

![回滚记录]()

当系统中没有比回滚记录更早的`read-view`时，将删除回滚记录。因此不建议使用长事务，长事务意味着系统中存在很老事务视图，事务不提交，相关的回滚日志将占用大量存储空间。

## 事务启动方式

- `set autocommit=1`，然后显式启动事务语句`begin`或`start transaction`，提交语句`commit`，回滚语句`rollback`。针对频繁使用事务，可以采用`commit work and chain`语法，提交事务后自动启动下一个事务，节省再次执行begin的开销。

```mysql
START TRANSACTION | BEGIN [WORK]
COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]
ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]
SET AUTOCOMMIT = 1;
```

- 查询表中长于`60S`的长事务：`select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)>60);`

## 如何避免长事务对业务的影响？

- 应用开发端
  - 确认是否使用了`set autocommit=0`：可以通过`general_log`搭配业务逻辑判断。
  - 确认是否有不必要的只读事务。
  - 连接数据库时，通过`SET MAX_EXECUTION_TIME`控制每条语句最大执行时间。
- 数据库端
  - 监控`information_schema.innodb_trx`表，设置长事务阀值，超过即报警。
  - pt-kill工具
  - 业务功能测试阶段输出所有的general_log，提前分析。
  - 版本大于5.6，将`innodb_undo_tablespaces`设置大点。

# 索引

索引的目的是为了提高数据查询的效率，类似书籍的目录。

## 索引常见的模型

- 哈希表：哈希表只适合等值查找，但不适合范围查找。
- 有序数组：有序数组只适合静态存储引擎，适用于等值查找和范围查询。
- 搜索树：二叉搜索树的特点是左子节点<父节点<右子节点，查询的复杂度为`O(log(N))`，更新的时间复杂度为`O(log(N))`。为了尽可能查找数据，可以采用N叉树，减少访问磁盘次数，N叉树的N值可以通过page大小来间接控制，调整key的大小。

## InnoDB索引模型

`InnoDB`中，表是根据主键顺序索引的形式存放，这种表被称作为索引组织表。`InnoDB`中采用`B+`树作为索引模型，因此所有的数据都存储在`B+`树中。主键创建的索引树(聚簇索引)中，每个叶子节点存储的是整行数据。非主键创建的索引树(二级索引)中，叶子节点存储主键的值，因此基于非主键索引的查询会多扫描一颗索引树。

为了维护索引树有序性，插入新值时，需要挪动后续数据，挪出空位，此时还可能触发分裂，影响数据页利用率。删除数据时也可能发生数据页合并。基于这一点来考虑主键是否应该自增`NOT NULL PRIMARY KEY AUTO_INCREMENT`。

- 自增场景：自增场景下，插入数据是有序插入，因此不会出现叶子节点分裂；而且主键长度越小，普通索引的叶子节点也越小，普通索引占用空间也越小。
- 在KV场景下，就可以直接将业务字段作为主键，避免每次查询两颗树。

## 重建索引

索引重建：因为删除或页分离，导致数据页空洞，通过索引重建，重新将数据按序插入，提高页面利用率。

- 重建主键索引：主键索引不论删除还是创建，都会导致整个表重建，因此推荐使用`alter table T engine=InnoDB;`
- 重建非主键索引：适用于删除索引后再重建。

```mysql
alter table T drop index x;
alter table T add index x;
```

## 覆盖索引

查询过程中，如果通过非主键索引查询时，需要回主键索引树搜查(回表操作)。覆盖索引通过在非主键索引树中添加额外信息，覆盖查询需求，通过减少树的搜索次数，显著提升查询性能，但维护索引字段也需要付出一定的代价。

```mysql
CREATE TABLE `tuser` (
	`id` int(11) NOT NULL;
    `id_card` varchar(32) DEFAULT NULL,
    `name` varchar(32) DEFAULT NULL,
    `age` int(11) DEFAULT NULL,
    `is_male` tinyint(1) DEFAULT NULL,
	PRIMARY KEY(`id`),//主键索引
    KEY `id_card` (`id_card`)，
    KEY `name_age` (`name`,`age`) //覆盖索引
) ENGINE=InnoDB;
```

## 最左前缀原则

覆盖索引引发出一个问题，总不能为所有的查询请求建立索引？B+搜索树中，索引项是按索引中定义字段的顺序排序，因此可以通过前缀查询`like 'XXX%'`，查找到第一个符合条件的记录后，再往后遍历，加速检索速度。建立联合索引时的核心时，如何安排字段的顺序。示例：要支持身份证号获取姓名

- 索引复用能力：如何能少维护一个索引。
- 空间：选择字段小的建立单字段所有。

## 索引下推优化

MySQL5.6引入索引下拉，可以在索引遍历过程中，先使用索引中包含的字段做判断，过滤掉不符合条件的记录，减少回表次数。`select * from tuser where name like '张%' and age =10 and is_male=1`。

## 索引结构

```mysql
CREATE TABLE `geek`(
	`a` int(11) NOT NULL,
	`b` int(11) NOT NULL,
	`c` int(11) NOT NULL,
	`d` int(11) NOT NULL,
	PRIMARY KEY (`a`,`b`),
    KEY `c` (`c`),//创建的非主键索引结构 c a b
    KEY `ca` (`c`,`a`),// 创建的非主键索引结构 c a b
    KEY `cb` (`c`,`b`),//创建的非主键索引结构 c b a
)ENGINE=InnoDB;
```

# 锁

数据库锁设计的初衷是解决并发问题，MySQL中，锁可以分为全局锁、表级锁和行锁。

## 全局锁

全局锁将对整个数据库实例加锁，MySQL可以使用指令`Flush tables with read lock`加锁，加锁后整个库处于只读状态，会阻塞数据更新语句、数据定义语句和更新类事务的提交。全局锁通常用于全库的逻辑备份。

- 主库备份：备份期间，不能执行更新，业务处于停摆状态。
- 备库备份：备份期间，备库不能执行主库同步的binlog，导致主从不一致。

### 疑问

- 为什么需要使用全局锁呢？

  假设有两个表，余额表和用户课程表，假设我们的业务逻辑是先扣款，然后再用户课程表中添加课程。这样就可能出现如下流程：备份余额表后再进行扣款，然后再更新用户课程信息，然后再备份用户课程表。因此备份信息中存储的信息为扣款前的余额和购买成功后的用户课程，使用该备份恢复时，用户会出现少扣款的现象。

- 为什么不使用可重复读隔离级别来替代FTWRL？

  官方自带的`mysqldump`备份工具，如果使用`--single-transaction`参数时，再备份之前会启动一个事务，拿到一致性视图，由于MVCC的支持，整个过程中可以正常更新。但不是所有的数据引擎都支持事务，当表采用了不支持事务的引擎时，只能采用FTWRL方法。

- 为什么不采用`set global readonly=true`？

  `readonly`可以让全库进入只读状态，但有时某些系统会用`readonly`做一些逻辑判断，如判断是主库还是从库。另一方面，执行FTWRL后，如果出现异常导致客户端断开，MySQL会自动释放全局锁，但是`readonly`会导致数据库长时间处于不可写状态。

## 表级锁

MySQL中，表级锁有两种：表锁和元数据锁。

表锁的语法是`lock tables t1 read，t2 write`，表锁和FTWRL类似，可以采用`unlock tables`主动释放锁，也可以在客户端断开时自动释放。多线程情况下，表锁会影响所有的线程，直到执行`unlock tables`位置。

MySQL5.5中引入元数据锁，它的作用是保证读写的正确性，访问表时会自动添加。增删改查表会添加MDL读锁，结构变更会添加MDL写锁，读锁之间互不排斥，但写锁和读锁、写锁之间是互斥的。

为表添加字段、修改字段或加索引，需要遍历全表的数据，在对大表操作时，耗时非常长。但是针对小表，也需要谨慎操作。如果一个表上查询语句频繁，客户端也有重试机制，可能出现读锁导致后续的写锁操作阻塞，写锁操作又导致后续的读锁阻塞，这时超时机制会新起一个session再请求，很快库的线程就会爆满(MDL锁在语句执行时申请，语句结束后不会立即释放，整个事务提交后才会释放)。

- 如何安全为小表添加字段？

  采用`alter table NOWAIT/WAIT n`，设置等待时间，如果在这个时间内没有获取到MDL锁，则放弃操作。后续进行重试该操作。

  ```mysql
  ALTER TABLE tab_name NOWAIT/ add ...
  ```

## 行锁

行锁由引擎层实现，因此不是所有的引擎都支持行锁。不支持行锁的引擎意味着并发控制只能用表锁，同一张表上同一时刻只能有一个更新操作，印象业务并发度。

### 二阶段锁

行锁是针对数据表中行记录的锁，同一时刻，一个行记录只能有一个事务执行更新操作。行锁只在需要的时候添加上，但是释放操作只在事务结束时才会释放(二阶段锁)。这意味着即使使用行锁也会出现冲突。

![行锁冲突]()

二阶段锁告诉我们，如果事务中有多个锁，要把最可能出现锁冲突，最可能影响并发度的锁尽量往后放。

### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，每个线程都在等待其他线程释放资源，则会进入死锁状态。

![死锁]()

针对死锁，有两种策略：

- 超时等待，通过参数`innodb_lock_wait_timeout`，默认值为`50S`。第一个被锁住的线程超时后，主动 退出，释放资源。
- 死锁检测，`innodb_deadlock_detect=on`打开，发现死锁后，将主动回滚一个事务，让其他事务得以执行。

超时等待机制存在一个比较严重的问题：难以设置一个恰当的超时时间。超时时间短，容易出现误杀；超时时间过长，线程难以承受。

主动死锁检测机制是依赖于它所依赖的IO，在发生死锁时，会进行遍历检测，时间复杂度为`O(n)`，如果有`n`个线程，那么死锁检测的时间复杂度为`O(n^2)`，这会导致消耗大量CPU资源。

针对热点行中死锁检测导致的性能问题，可以有两种方式应对：

- 确保业务不会出现死锁，可以关闭死锁检测，但如果出现死锁，就会出现大量的超时。

- 服务端控制并发，针对相同行的更新，进入引擎之前先排队。

- 将一行逻辑上拆分为逻辑上的多行，减少锁的冲突。例如，修改影院账户的金额，可以拆分为10行，每次添加、减少金额时，随机选择一行，锁冲突概率变为了`1/10`，可以减少死锁检测的CPU消耗，但是业务逻辑上需要更详细的设计。


