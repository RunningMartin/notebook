# 基础写作

## 文件操作

### 基础介绍

Python将文件视作为一个字节流，以字节为单位，从头到尾读取文件中的数据，因此已经被读取的字节不能再被读取(除非重新创建一个字节流)。

![字节流](基础写作/字节流.png)

Python内置文件操作函数`open`，其语法格式为：

```python
open(file_path:str,mode:str='rt',encoding:str=None)
```

- `file_path`：文件的路径，该参数必需。
- `mode`：文件操作模式，默认为`rt`，即采用文本读模式。
- `encoding`：读写文件时的编码格式，如`utf-8`。

`open`函数支持文件操作模式分为两部分：读写模式和读写时数据类型。

表1、读写模式

| 模式  | 意义                |
| :---- | :------------------ |
| r | 只读模式(默认)      |
| w | 写模式，从头写      |
| x | 写模式，如果文件存在则报错 |
| a | 追加模式            |
| + | 模式升级为读写模式，搭配`r`、`w`、`a`使用，如`r+`表示读写模式 |

表2、读写时数据类型

| 模式  | 意义                |
| :---- | :------------------ |
| b | 二进制类型，可搭配`r`、`w`，如`rb`表示二进制读 |
| t | 字符串类型 |

### 文件读

`open`函数会返回一个文件句柄，常用的读操作有：

- `read(字节数)`：读取指定字节数。
- `readline([字节数])`：读取一行内容，如果指定了字节数，则读取该行指定字节数。
- `readlines()`：读取所有行。

`readline`是通过换行符(Linux为`\n`、Windows为`\r\n`、Mac为`\r`)来识别行，因此读取行时，如果没有指定字节数，则读到换行符时结束读写。

```python
# read_test.txt文件内容
In[1]: %cat read_test.txt
第一行：1234567890
第二行：2345678901
第三行：3456789012
第四行：4567890123
第五行：5678901234
In[2]: file = open("read_test.txt", 'r')
# 读第一行前10个字符
In[3]: file.read(10)
Out[3]: '第一行：123456'
# 读第一行剩余字节，因为第一行未读取完
In[4]: file.readline()
Out[4]: '7890\n'
# 读第二行前10个字节
In[5]: file.readline(10)
Out[5]: '第二行：234567'
# 读取剩余所有行
In[6]: file.readlines()
Out[6]: ['8901\n', '第三行：3456789012\n', '第四行：4567890123\n', '第五行：5678901234']
# 关闭文件句柄
In[7]: file.close()
```

### 文件写

文件写时有一个非常重要的概念：**文件指针**。文件指针表示当前读写数据时的字节位置。`a`和`a+`打开文件时，文件指针位于文件结尾处。`r+`、`w`或`w+`打开文件时，文件指针在文件开始位置，但`w`、`w+`会清空文件内容。

![文件指针](基础写作/文件指针.png)

文件指针支持两个操作：

- `tell()`：获取当前文件指针位置。
- `seek(offset[,whence=0])`：将文件指针移动到指定位置`whence+offset`。

```python
In[1]:%cat test_write.txt
test_write已有内容
12345
In[2]:file = open('test_write.txt','r+')
In[3]:file.tell()
Out[3]: 0
In[4]:file.read(1)
Out[4]: 't'
In[5]:file.tell()
Out[5]: 1
In[6]:file.seek(5)
Out[6]: 5
In[7]:file.read(1)
Out[7]: 'w'
In[8]:file.close()
```

文件对象提供了两个写文件方法：

- `write(s)`：`s`为写入的内容。
- `writelines(lines)`：`lines`是一个可迭代对象，写入多个内容。

```python
# 采用追加模式
In[1]: %cat test_write.txt
test_write已有内容
12345
In[2]: file = open('test_write.txt','a+')
In[3]: file.write('new info')
Out[3]: 8
In[4]: %cat test_write.txt
test_write已有内容
12345new info
In[5]: lines=['123','456','789']
In[6]: file.writelines(lines)
In[7]: file.close()
In[8]: %cat test_write.txt
test_write已有内容
12345new info123456789
```

## 多进程

现代操作系统中每个程序都是运行在某个进程的上下文中。上下文由程序正确运行所需的资源组成，包含存储器中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器（PC）、环境变量以及打开的文件描述符的集合。操作系统以进程为单位分配资源，初始化时，会在内存中为进程分配一块独立的空间，进程由操作系统负责调度与管理。

进程主要提供给上层应用两个抽象：

- 独立的逻辑控制流：它提供一个抽象，即该进程独占处理器。
- 私有的虚拟地址空间：它提供一个抽象，即独占存储系统。

Linux中通过`fork`创建的子进程，将获得父进程的虚拟地址空间的拷贝，包括文本、数据和`bss`段、堆以及用户栈等，因此子进程可以读写父进程打开的文件，父子进程最大的区别是`PID`(进程ID)不同。

### 进程创建

`multiprocessing`模块支持三种创建进程的方式，即：

- `spawn`：通过`spawn`创建的子进程从父进程中继承运行进程的必要资源，因此启动进程速度慢。Unix和Windows都支持`spawn`，Windows上默认采用`spawn`。
- `fork`：`fork`通过直接复制父进程来创建子进程，因此效率很高(有坑，多线程并不安全)，只有Unix支持`fork`，而且是Unix默认采用的方法。
- `forkserver`：`forkserver`会先创建一个单线程服务器进程，当需要创建新进程时，父进程请求服务器，从服务器进程中`fork`一个子进程，因此`fork`时是安全的，但不是所有的Unix平台都支持。

`multiprocessing`提供两个API，用于设置创建进程的方式：

- `set_start_method(方法名)`：全局设置，作用于整个`multiprocessing`模块，因此不能被多次调用。
- `get_context(方法名)`：返回一个上下文，只作用于该上下文。

这里需要注意的是，从不同类型上下文中获取的对象不要混用， 如`fork` 上下文创建的锁不能传递给通过`spawn` 或 `forkserver`上下文启动的进程。

```python
def hello(name):
    from os import getpid
    import random, time
    time.sleep(random.randint(1, 5))
    print(f'hello {name}, I am {getpid()}')


from multiprocessing import get_context

if __name__ == '__main__':
    context = get_context('spawn')
    # 或直接multiprocessing.Process 通过默认方式创建进程
    process1 = context.Process(target=hello, args=('martin',))
    process2 = context.Process(target=hello, args=('martin',))
    for p in [process1, process2]:
        p.start()
    for p in [process1, process2]:
        p.join()
```

`Python`还提供了进程池`Pool`，进程池提供了五个函数，用于创建多个进程，并行执行：

- `map(func,iterable)`：`func`是进程需要执行的函数，`iterable`是参数
- `map_async(func,iterable)`：
- `imap_unordered(func,iterable)`：
- `imap_unordered(func,iterable)`：
- `apply_async(func,args)`：

```python
import time
from multiprocessing import Pool

def hello(name):
    from os import getpid
    import time
    time.sleep(2)
    return f'hello {name}, I am {getpid()}'


def test_map(pool, names):
    start = time.perf_counter()
    # 返回的结果是和iterable的顺序相同
    # map是同步方法，直到其结果返回才会进行下一行代码
    print("print map result")
    print(pool.map(func=hello, iterable=names))
    end = time.perf_counter()
    print(f"Used :{end-start}")


def test_map_async(pool, names):
    """异步执行map"""
    start = time.perf_counter()
    # map_async命令下发后，会立即返回，不会在该处阻塞
    result = pool.map_async(func=hello, iterable=names)
    print("print map_async result")
    # 获取结果时会阻塞，查看源码map_async和map的区别在于，map中调用了get方法
    print(result.get())
    end = time.perf_counter()
    print(f"Used :{end-start}")


def test_imap_unordered(pool, names):
    """map_async的乱序版本"""
    start = time.perf_counter()
    # 乱序执行
    result = pool.imap_unordered(func=hello, iterable=names)
    for r in result:
        print(r)
    end = time.perf_counter()
    print(f"Used :{end-start}")


def test_apply(pool, names):
    """同步执行apply，apply函数只使用一个核，因此其耗时因此是单个耗时*len(names)"""
    start = time.perf_counter()
    print("print apply")
    result = [pool.apply(func=hello, args=(name,)) for name in names]
    print(result)
    end = time.perf_counter()
    print(f"Used :{end-start}")


def test_apply_async(pool, names):
    """异步执行apply方法"""
    start = time.perf_counter()
    print("print apply async")
    # 异步执行
    result = [pool.apply_async(func=hello, args=(name,)) for name in names]
    for r in result:
        print(r.get())
    end = time.perf_counter()
    print(f"Used :{end-start}")


if __name__ == '__main__':
    with Pool(processes=4) as pool:
        names = ['martin', 'ana', 'liming', 'Kev']
        test_map(pool, names)
        test_map_async(pool, names)
        test_imap_unordered(pool, names)
        test_apply(pool, names)
        test_apply_async(pool, names)
```

### 进程间通信

进程可以通过`fork`和`spawn`创建新的进程，但是新进程有自己独立空间，因此进程之间通信只能采用进程通信机制(IPC)，如管道、信号、套接字、共享空间。Python的标准库`multiprocessing`支持队列和管道。

#### 队列

```python
from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
    p.join()
```

#### 管道

当两端同时对管道的一端写入或读取时，数据可能损坏。

```python
from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    p = Process(target=f, args=(child_conn,))
    p.start()
    print(parent_conn.recv())   # prints "[42, None, 'hello']"
    p.join()
```

### 进程间同步

`multiprocessing`提供锁来实现进程间同步，确保同一时刻只有一个进程执行该操作。

- 互斥锁(Lock)：同一时刻只能有一个进程获取该锁。
- 递归锁(RLock)：同一个进程可以在不释放锁的情况下，多次获取该锁。

```python
from multiprocessing import Lock, RLock

def test_lock():
    lock = Lock()
    print("获取互斥锁")
    lock.acquire()
    print("再次获取互斥锁")
    lock.acquire()
    print("释放互斥锁")
    lock.release()

def test_rlock():
    rlock = RLock()
    print("获取递归锁")
    rlock.acquire()
    print("再次获取递归锁")
    rlock.acquire()
    print("释放递归锁")
    rlock.release()
    rlock.release()

if __name__ == '__main__':
    test_rlock()
    test_lock()
```