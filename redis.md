# Redis学习

## 灵魂拷问

- Redis是什么？
- Redis能用来做什么？
  - 缓存
  - 分布式锁

## 基础数据结构

- `Redis`中所有数据结构都是以唯一的`key`字符串作为名称，通过`key`来获取相应的`value`数据。不同类型的数据结构差异在`value`的结构。
- 字符串(`string`)：
  - 其`value`为一个字符串，其字符串是一个动态字符串，通过预分配冗余空间来避免频繁内存分配。当字符串长度小于`1M`，扩容每次都加倍，如果超过`1M`,每次只扩容`1M`，字符串最大长度为`512M`。
  - 应用场景：可以用于缓存用户信息(搭配序列化与反序列化)。
- 列表(`list`)：
  - 底部实现为链表，插入、删除操作非常快，时间复杂度为`O(1)`。索引的时间复杂度为`O(n)`(会进行遍历)。
  - 当列表为空时，内存会自动回收。
  - 应用场景：异步队列，将任务结构体序列化后，放入列表，另一端从列表中获取数据进行处理。
  - 类型：
    - 队列：一边进一边出。
    - 栈：固定一个方向进、出。
  - 快速列表：元素较少时，采用连续内存空间存储(压缩列表：`ziplist`)，当元素较多时，改为`quicklist`，这是因此指针也需要空间。`quciklist`将多个`ziplist`通过双向指针串起来，实现快速插入删除性能的同时，又不会出现太大的空间冗余。
- 集合(`set`)：集合是一个特殊的字典，其`value`值为`NULL`，内部的键值对是唯一且无序的。
- 哈希(`hash`)：
  - 哈希是无序字典，其采用数组+链表的二维结构，数组用于存储`hash`值，链表用于存储碰撞的元素。其值只能是字符串，`Redis`为了提高性能，不阻塞服务，采用渐进式`rehash`策略(rehash  的同时，保留新旧两个  hash  结构，查询时会同时查询两个hash结构，然后在后续的定时任务中以及hash的子指令中，循序渐进地将旧  hash  的内容一点点迁移到新的  hash  结构中)
  - 哈希可以用于存储、读取、修改用户属性，数据传输量比字符串小，但是其存储消耗高。
- 有序集合(`zset`)：
  - `zset`是一个集合，但是可以为每个元素赋予一个`score`，代表其排序权重。
  - 可以用于排行榜、需要使用权重信息。
  - 跳跃列表：`zset`要实现随机插入与删除，因此不能采用数组来存储，但是又要实现排序，也就意味着新元素插入时，需要知道要插入到哪里，这样才能维持链表有序。查找插入点最快的方法莫过于二分法，二分法其对象必须是数据，因此可以采用这种思想，为链表定制一个能快速定位的层级结构，以空间换时间。
- 基本库：`redis-py`

## 操作

- 添加键值对
  - 单个：`set key value`
  - 多个：`mset key1 value1 key2 value2 key3 value3`
- 查询`value`值
  - 单个：`get key`
  - 多个：`mget key1 key2 key3`
- 删除：`del key`
- 判断键是否存在
  - `exists key`
  - 不存在则只需`set`：`setnx key value`
- 设置过期时间(可以用于控制缓存失效时间)：
  - `expire key time(单位秒)`
  - 执行`set`且设置过期时间：`setex key time value`
- 计数(当value为一个整数时，可以进行递增，其范围为`signed long`)：`incrby 键 增量`
- 列表操作：
  - 添加元素：
    - `rpush 列表名 value1 value2`：在列表右边添加元素。
    - `lpush 列表名 value1 value2`：在列表左边添加元素。
  - 获取元素：
    - `rpop 列表`：从列表右边获取元素。
    - `lpop 列表`：从列表左边获取元素。
  - 获取长度：`llen 列表`。
  - `lindex 列表名 序号`：根据序号获取元素，可以为负值，表示倒数，通过遍历实现。
  - `lrange 列表名 起始 结束`：获取列表中一段元素。
  - `ltrim 列表 起始 结束`：定义区间，区间外的元素丢弃，实现定长列表。
- 字典操作
  - 创建：
    - 单个：`hset 字典名 key value`
    - 多个：`hmset 字典名 key1 value1 key2 value2`
  - 获取所有信息：`hgetall 字典名`，以键 值间隔出现
  - 获取字典长度：`hlen 字典名`。
  - 计数：`hincrby 字典名 键 增量`
- 集合
  - 添加元素：`sadd 集合名 key1 key2`。
  - 查看元素：`smembers 集合名`。
  - 判断是否存在：`sismember 集合名 key1`
  - 获取长度：`scard 集合名`
  - 弹出一个元素：`spop 集合名`
- 有序集合
  - 添加元素：`zadd 集合名 权重 元素`
  - 顺序排序：`zrange 集合名 起始位置 结束位置`
  - 倒序排序：`zrevrange 集合名 起始位置 结束位置`
  - 统计：`zcard 集合名`
  - 获取权重信息：`zscore 集合名 元素`
  - 获得排名：`zrank 集合名 元素`
  - 获得权重范围内的元素：`zrangebyscore 集合名 起始权重 结束权重`
  - 带权重信息：`zrangebyscore 集合名 起始(inf代表无穷大) 结束 withscores`
  - 删除元素：`zrem 集合 元素`
- 通用规则
  - 不存在则创建
  - 没有元素则删除
  - 过期时间：过期时间是以对象为单位的，而不是由其中一个子key决定，对一个字符串设置了过期时间，但是调用了`set`修改了，则过期时间会消失(是否所有都是的)。
    - 查看过期时间：`ttl 键`

## 应用

### 分布式锁

- 概念：并发编程中，当遇到修改共享资源时，必须确保其操作是原子的(不会被线程调度机制打断)，原子性操作很难实现，但是可以通过加锁来实现。分布式锁是用来保证分布式应用中，多个节点同一时刻只有一个线程在操作该资源。

- 实现：通过标志位来告知其他进程其已经被使用了。

  - 拥有锁：`setnx key value`
  - 设置超时时间：`expire  key timeout`（防止死锁）
  - 释放锁：`del key`

- 问题：`setnx`和`expire`是两条独立的指令，并非原子操作，如果执行完`setnx`后，线程就挂了，则会导致死锁。

- 解决方案：`set key value ex timeout nx（不存在）`

- 超时问题：分布式锁不能解决超时问题，加锁与释放锁的时间间隔大于了超时时间，则会导致另一个线程会获取该锁，因此不要用于较长时间的任务。安全的方案是：`value`设置一个id(随机值或线程id)，释放锁时要匹配ud是否相同，然后再决定是否删除，需要`Lua`脚本处理，`Lua`可以保证多个指令原子性执行。

- 可重入性(递归锁)：需要包装`set`方法，通过`ThreadLocal`统计当前持有锁的计数。

  ```python
  # -*- coding: utf-8 
  import redis 
  import threading 
  locks = threading.local() 
  locks.redis = {} 
  def key_for(user_id): 
  	return "account_{}".format(user_id) 
  def _lock(client, key): 
  	return bool(client.set(key, True, nx=True, ex=5)) 
  def _unlock(client, key): 
  	client.delete(key) 
  def lock(client, user_id): 
      key = key_for(user_id) 
      if key in locks.redis:
      	locks.redis[key] += 1 
      	return True 
      ok = _lock(client, key) 
      if not ok: 
      	return False 
      locks.redis[key] = 1 
      return True 
  def unlock(client, user_id): 
      key = key_for(user_id) 
      if key in locks.redis: 
     		locks.redis[key] -= 1   
      	if locks.redis[key] <= 0: 
      		del locks.redis[key] 
     		return True 
      return False 
  client = redis.StrictRedis() 
  print "lock", lock(client, "codehole") 
  print "lock", lock(client, "codehole") 
  print "unlock", unlock(client, "codehole") 
  print "unlock", unlock(client, "codehole") 
  ```

  - 集群情况下，客户端从主节点中申请了一把锁后，还未同步到从节点，主节点挂掉，从节点取代后，没有这个锁，这时可能会出现将一把锁同时分配给两个客户端。高可用。
    - `Redlock`算法，`redlock-py`实现了封装。采用大多数机制，加锁时，将命令向超过一半的节点发送，只有当一半的节点成功后，才认为加锁成功，释放锁时，向所有节点发送指令，由于需要向多个节点进行读写，因此性能会下降。使用时要多加考虑。

- 锁冲突问题(加锁没有加成功)

  - 直接抛出异常，用户自行决定是否重试。
  - 睡眠一定时间重试：睡眠会阻塞当前消息处理线程，从而导致后续消息处理出现延迟，极端情况下，死锁会导致一直加锁不成功，线程被彻底堵死。
  - 将请求放置延时队列，延后处理。

### 延时队列

- 通过列表来实现异步消息队列，通过`lpush`和`rpush`入队，`lpop`和`rpop`出队。
- 队空：消费者不停的pop，判断数据，从而导致空查询，降低性能。可以通过pop后，为空数据，则睡眠一定时间，但这会导致消息延迟增大。解决方案：`blpop`或`brpop`进行阻塞读，从而解决空查询和延迟问题。
- 空闲连接：消费者一直阻塞，则会变为闲置链接，通常超过一段时间，服务器会主动断开链接，减少闲置资源占用，这时会抛出异常。
- 实现

```python
# 采用zset实现，将消息序列化作为value，到期时间作为score
def delay(msg): 
    msg.id = str(uuid.uuid4())    # 保证 value 值唯一 
    value = json.dumps(msg) 
    retry_ts = time.time() + 5     # 5 秒后重试 
    redis.zadd("delay-queue", retry_ts, value) 
def loop(): 
    while True: 
    # 最多取 1 条 
    values = redis.zrangebyscore("delay-queue", 0, time.time(), start=0, num=1) 
    if not values:   
        time.sleep(1)    # 延时队列空的，休息 1s 
        continue 
    value = values[0]   # 拿第一条，也只有一条 
    success = redis.zrem("delay-queue", value)    # 从消息队列中移除该消息，用于抢夺任务 
    if success:     # 因为有多进程并发的可能，最终只会有一个进程可以抢到消息 
    msg = json.loads(value) 
    handle_msg(msg) 
```

- 优化：`zerm`抢夺不到任务的进行执行时会有浪费，可以通过`Lua`将`zrangebyscore`和`zrem`变为原子化操作。
- 为什么不能保证`100%`可靠性：消息被发送出去，消费者是否接收到消息redis不做保证，不像一般的mq，会有ack机制，要求消费者收到消息进行ack确认，超时未确认mq会再次投递消息，而redis没有这个机制。

### 位图

- 位图：每个数据只占一位，可以用于在签到中，大大节省空间。其内容实际也是普通字符串(byte数组)，可以通过`get`、`set`对整个位图进行操作，也可以通过`getbit`、`setbit`进行位数组操作。位数组是自动扩展的，扩展时，以0扩充。
  - `setbit 名 位置 值(0|1)`
  - `getbit 名 位置`
  - 统计指定范围1的个数：`bitcount 名 起始 结束`，以字节为索引，因此范围必须是8的倍数。
  - 查找第一个值的位置：`bitpos 名 值 起始 结束`
  - 多个位处理：`bitfield 名 指令(get|set|incrby) 类型连续位数 起始位`，最多64个连续位(无符号64位，有符号63位)。
    - `bitfield w get i4 0 指令2`：从w中的第一个为开始，取四个位，结果是有符号数。
    - 递增时，溢出默认折返(默认`wrap`)，还可以报错(`fail`)和截断(`sat`停留在最值)
      - `bitfield w incrby u4 2 1`
      - `bitfield w overflow sat incrby u4 2 1`
      - ` bitfield w overflow fail incrby u4 2 1`

### HyperLogLog

- **PV(Page View)**、**UV(Unique visitor)**，使用场景：去重计数。
- 统计`UV`
  - 访问量小时，可以采用为每个页面建立一个`set`去存储当天访问过该页面的用户ID。
  - 访问量大的话，`set`会浪费大量空间，而且访问量很大的情况下，`UV`统计不必太准确。`HyperLogLog`数据结构提供不精确的去重计数方案，其标准误差在`0.81%`。
- 操作：
  - 添加元素：`pfadd 名 用户`
  - 获取计数：`pfcount 名`
  - 累加`pf`计数值(对数据进行合并)：`pfmerge 名1 名2 名3`
- 注意事项：会占用12K的存储空间，Redis中，计数比较小时，采用稀疏矩阵存储，当空间使用较大时，才会转变为稠密矩阵，占12k的空间。

### 布隆过滤器

- 用途：判断一个值是否已经存在了，从而实现去重。但是对没有见过的数据可能会预判为见过。redis 4.0中作为一个插件存在。
- 使用：
  - 添加元素：
    - 单个：`bf.add 名 值`
    - 多个：`bf.madd 名 值1 值2`
  - 判断是否存在：
    - 单个：`bf.exists 名 值`
    - 多个：`bf.mexists 名 值1 值2`
- 误判：
  - `bf.reserve .error_rate`：错误率，错误率越低，需要的空间越大。
  - `bf.reserve .initial_size`：预计放入的元素个数，如果实际超过，则误判率上升。
- 原理：大型位数组+不同的无偏`hash`函数(将hash计算均匀)
  - 添加一个`key`时，对`key`进行多次`hash`，将多个位置置为1。
  - 判断存储与否时，多`key`进行hash，只要有一个位置为`0`，则该key不存在，如果都是，则极大概率存在。
  - 如果实际元素远大于初始化值，应该对布隆过滤器进行重建。
- 空间预估：
  - 预估数量$n$
  - 错误率$f$
  - 长度($l$)：$f=0.6185^{l/n}$
  - hash函数数量($k$)：$ k=0.7 *(l/n) $

### 简单限流

- 限流通常用于控制流量，控制用户行为，避免垃圾请求。
- 目标：限定用户在指定时间内某个行为只允许发送N次。
- 解决方案：通过zset的score圈出滑动窗口，value采用毫秒时间戳。

## 原理

### IO模型

Redis是单线程程序，因此使用其复杂度为`O(n)`的指令时，容易出现卡顿。由于其所有的数据都是存储在内存中，因此其运算速度快。

- 单线程如何处理多并发客户端连接？

  Redis采用多路复用IO模型，其是非阻塞IO。

  - 阻塞IO：必须在缓冲区读写一定字节，如果条件不满足，则阻塞，直到完成任务。
  - 非阻塞IO：能往缓冲区读写多少就读写多少，通过返回值告知程序实际读写的字节数。

  非阻塞IO存在一个问题，即任务只完成了部分，当条件满足时，需要有一个机制来通知线程完成剩余任务。select函数提供事件轮训API。`select(read_fds,write_fds,timeout)`，将返回读写描述符对应的读写事件，如果在timeout时间内，有事件发生，则返回事件，如果超时，也直接返回(这一步是阻塞的)。当线程拿到时间后，则处理相应的时间，处理完后，继续轮训。通常多路复用使用的是`epoll`，因为`select`系统调用的性能在描述符多时性能非常差。

  - 指令队列：每个客户端关联到同一个指令队列，客户端指令在队列中排序，先到先服务。
  - 响应队列：每个客户端也关联到一个响应队列，服务器通过响应队列将结果返回客户端，如果队列为空，不调用写事件，避免无效消耗CPU。

  服务器除了响应IO事件外，还要处理其他事情，如定时任务，如果线程阻塞在select系统调用时，定时任务将无法准时调度。Redis会建立一个最小堆用于记录最快要执行的任务，每个循环周期，Redis要处理最小堆到点的任务，并且将新的最快要执行的任务所需时间作为select的timeout参数。

  ### 通信协议

  RESP通信协议，其特点：简单易实现

  - 单行字符串：`+helloworld\r\n`
  - 多行字符串：`$11\r\nhelloworld\r\n`
  - 整数：`:1024\r\n==1024`
  - 错误消息：`-错误信息`
  - 数组：`*3\r\n:1\r\n:2\r\n:3\r\n==[1,2,3]`
  - NULL：`$-1\r\n`
  - 空串：`$0\r\n\r\n`

### 持久化

持久化机制用于保证Redis的数据不会因为故障而丢失。Redis的持久化机制有两种：快照和AOF日志

#### 快照

快照是一次全量备份，将内存数据进行二进制序列化，在存储上非常紧凑。Redis是单线程程序，如果让在处理多个客户端的请求同时还有处理内存快照，这会严重拖累服务器请求性能，因为快照时文件IO操作，文件IO操作不能使用多路复用API，而且持久化的同时，内存结构还在变化，这导致实现太过于复杂。

Redis采用操作系统的多进程COW机制实现快照持久化。Redis在持久化时，调用fork函数，生成子进程，子进程负责快照持久化，子进程生成时，将和父进程共享内存资源。子进程负责对数据结构进行遍历，然后序列化写到磁盘中。父进程在对数据进行修改时，会使用到COW机制来进行数据段页面的分离(一个数据段由多个页面组成，每个页面4K大小)，当父进程对其中一个页面修改时，会将共享的页面复制一份，父进程对复制页面进行修改，因此子进程的页面没有变化。最终内存的不会增长太大。

#### AOF日志

连续的增量备份，记录内存数据修改的指令，因此会随着运行而变得庞大，数据库重启时，需要加载AOF日志进行指令重放，因此需要及时对AOF日志瘦身。Redis收到一个修改指令后，进行参数校验，然后存储到磁盘中，在执行指令。因此出现宕机也可以重放日志指令，恢复到宕机之前的状态。

bgrewriteaof指令用于AOF日志瘦身，其原理是将通过子进程遍历内存数据，转换为Redis操作指令，然后序列化为一个新的AOF日志，再将操作期间的增量AOF追加过去。

对AOF日志的写操作，实际是将内容写到内核的内存缓存中，由内核异步将脏数据刷回磁盘。可以通过`fsync`函数请知刷盘，但这是一个磁盘IO操作，速度慢，通常Redis每隔1S刷新一次，可以配置。

快照和AOF日志都会消耗一定的资源，因此通常Redis的主节点不会进行持久化操作，持久化操作主要在从节点执行。这

#### 混合持久化

将快照和增量的AOF日志存在一起，从而先加载快照，再重放AOF日志，提高重启效率。

### 管道

通常，Redis客户端执行一条指令时，需要两个操作，即：写—读，这需要花费一个网络数据包来回时间，如果是n条指令，就需要花费n个网络数据包来回时间。为了节约时间，最佳的方案是客户端拥有两个管道，一个管道负责发送指令、一个管道负责读取结果，可以节约大量IO时间。

管道压力测试工具：redis-benchmark

```
 # 测试set命令压力
 redis-benchmark -t set -q
 # -P 单个管道内并发请求的数量，其极限是CPU的处理能力
 redis-benchmark -t set -P 2 -q
```

#### 管道本质

客户端通过改变读写的顺序带来的性能提升。

截图

write是往内核发送缓冲中写数据，因此其基本没有耗时，只有当发送缓冲满了，才需要等待缓冲空出空闲空间，这个时间为写操作IO操作的耗时；read是从内核接收缓冲中读数据，也基本没有耗时，只有当接收缓冲空时，才需要等待数据到来，这个时间为读操作IO操作的耗时。因此对于管道来说，连续的write操作基本没有耗时，而第一个read会等待一个网络的来回开销，后续read操作也基本没有耗时，直接从缓冲中拿数据。

### 事务

事务：用于确保多个操作的原子性。`multi`：事务开始，`exec`：执行事务，`discard`：事务的丢弃，exec之前执行。Redis会将多条命令缓存到事务队列中，当执行`exec`指令时，才会执行事务，由于Redis的单线程特性，不必担心执行队列时被其他指令干扰，保证了事务的隔离性，但是事务遇到指令执行失败后，后续指令还会继续执行。因此Redis的事务没有原子性。

优化：采用管道执行指令

watch：乐观锁，watch会在执行事务之前关注一个或几个关键变量，当收到exec指令时，会检查关键变量是否发生变化，如果发生变化，则返回null，事务执行失败。，因此watch必须在multi之前执行。

Redis的事务为什么不支持回滚呢？

只有当Redis命令有语法错误或对某个键执行不支持的操作时，才会导致命令失败，这两种错误都是程序带来的错误，而回滚并不能解决任何程序错误，这些问题在开发期间会被解决，因此Redis在系统内部对功能进行了简化，确保更快的运行速度。

### PubSub

Redis的消息队列不支持多播机制。

消息多播允许生产者生成一次消磁，中间件将其复制的多个消息队列中，由消息队列对应的消费组进行消费，为了支持消息多播，Redis提供PubSub(发布者订阅者模型)。

```
# 订阅
subscribe 主题1 主题2 主题3
# 发布消息
publish 主题 消息
# 模式订阅：通过通配符，批量订阅，订阅以code.开头的主题
psubscribe code.*
```

缺点：生产者传递一个消息给Redis，Redis将消息传递给相应消费者，如果没有消费者直接丢弃，如果有一个消费者挂掉后，重新连接上， 这段时间内生产者发送的消息，对于该消费者来说，是彻底丢失了。而且还存在另一个问题，如果Redis停机重启，PubSub的消息不会持久化(宕机意味着没有消费者，消息直接丢弃)

Stream

Stream是一个支持多播的可持久化消息队列，来源于Kafka。通过一个消息链表，将所有的消息串联起来，并且每一个消息有一个为一个ID，一个Stream支持多个消费组，每个消费者会有一个游标last_delivered_id用于表示该消费组消费到哪条消息。不同的消费组之间互不影响。一个消费组中有多个消费者，消费者之间存在竞争关系，任意一个消费组读取了消息都会导致消费组的last_delivered_id前移，消费者内维护pending_ids，记录当前被客户端读取的消息ID，但是还没有ack，用于确保客户端至少消费了消息一次，且不会因为网络传输丢失导致没有处理。

消息ID的形式为` timestampInMillis-sequence`，消息的内容为键值对。

命令

- 添加消息：`xadd stream名称 ID(*表示自动生成) key1 value1 key1 value1`
- 删除消息：`xdel stream名称 消息ID `，只是置标志位，不会影响消息总长度。
- 获取消息列表：`xrange stream命令 起始ID(最小值：-) 结尾ID(最大值：+)`，会过滤已经删除的
- 消息长度：`xlen stream名称`
- 删除stream：`del stream名称`
- 独立消费：`xread 指令 streams 名称1 名称2 起始ID`，没有消费组的情况下进行消费。
  - `count 数量`：限制读取的数量
  - `block 时间`：阻塞超时时间，0则一直阻塞
  - `0-0`：最开始位置
  - `$`：从尾部开始，只接受新消息
- 创建消费组：`xgroup create stream名称 消费组 起始ID`
- 查看流信息：`xinfo stream 流名称`
- 查看消费组信息：`xinfo groups 流名称`
- 查看消费者信息：`xinfo consumers 流名称 消费组`
- 消费信息：`xreadgroup GROUP 消费者组 消费者 指令 streams 流名称 >`
  - `count 数量`
  - `block 时间`：阻塞超时时间，0则一直阻塞
- ack消息：` xack 流名称 消费者组 消息ID`

定长Stream：`xadd 流名称 maxlen 长度 id key1 value1`，能清理就消息

Stream在每个消费者结构中保存了正在处理的消息ID列表PEL，如果消费者收到再消息处理完但没有ack，会导致PEL列表不断增长。当消费者读取流消息时，服务器将消息回复给客户端的过程中，客户端断开链接后，重连上，能再次收到PEL中的消息列表，但此时`xreadgroup`的起始ID不能为`>`，应该为有效的消息ID，通常为`0-0`,读取PEL消息以及last_delivered_id之后的新消息。

##### 高可用性

Stream的高可用建立在主从复制的基础上，但是复制是异步的，因此可能会丢失部分数据。Redis可以通过分配多个Stream来实现分区，客户端采用一定的策略将生产的消息发送到不同的stream中。

### 小对象压缩

Redis所有的数据都是存放在内存中，因此如果不优化数据结构的内存占用，会导致内存不足而崩溃，如果使用内存不超过4G，最好采用32bit进行编译，内部所有数据结构使用的指针空间占用会少一半，不足可以通过添加实例来解决。

小对象压缩：如果集合数据结构很小，会采用紧凑存储形式压缩存储，如果hashmap当内部元素少时，二维结构浪费空间，可以采用一维数组存储。

ziplist是一个紧凑字节数组结构。

```
hset 名 key value
object encoding 名
```

hash结构的数据，key与value相邻存储，zset，value和score相邻存储。`intset`是一个紧凑的整数数组结构，用于存放元素为整数且元素个数较少的set集合，其支持unint16、unint32、unint64。当元素个数超过界限或某个value值过大，则会变为标准结构

hash-max-zipmap-entries 512   # hash 的元素个数超过 512 就必须用标准结构存储
hash-max-zipmap-value 64   # hash 的任意元素的 key/value 的长度超过 64 就必须用标准结构存储
list-max-ziplist-entries 512   # list 的元素个数超过 512 就必须用标准结构存储
list-max-ziplist-value 64   # list 的任意元素的长度超过 64 就必须用标准结构存储
zset-max-ziplist-entries 128   # zset 的元素个数超过 128 就必须用标准结构存储
zset-max-ziplist-value 64   # zset 的任意元素的长度超过 64 就必须用标准结构存储
set-max-intset-entries 512   # set 的整数元素个数超过 512 就必须用标准结构存储

内存回收机制

Redis不会实时将空闲的内存释放给操作系统，因为操作系统回收内存是以页为单位，如果该页上有一个key未被删除，则不能回收，通常key都是分散分布在不同页面上。执行flushdb会强制回收，因为会删除所有的key。Redis无法保证立即回收已经删除的key的内存，但他会重用未被回收的空闲内存。

内存分配算法：要划分内存页，考虑内存碎片，平衡性能和效率、

Redis的内存分配细节由第三方内存分配库负责，如jemalloc，tcmalloc。默认为jemalloc

```
# 查看内存
info memory
```

### 主从同步

现代分布式系统理论基石：CAP原理(网络分区(网络端口，出现节点连不上)发生时，无法满足一致性，只能通过牺牲可用性(暂停服务)，等待网络恢复后，再继续对外提供服务)

- 一致性(Consistent)
- 可用性(Availability)
- 分区可容忍性(Partition tolerance)

Redis的主从数据是异步同步的，所以分布式的Redis并不满足一致性要求，只满足可用性，但Redis保证最终一致性(从节点努力追赶主节点，最终主从状态一致)，一旦出现网络分区现象，则主从会出现大量不一致。当网络恢复后，从节点会努力追赶。Redis支持主从同步、从从同步。

- 增量同步：Redis同步的是指令流，主节点将对状态有修改的指令记录在buffer中，然后异步将指令同步给从节点。buffer是一个定长环形数组，如果数组内容满了，则会从头开始覆盖。因此可能出现未被同步的指令被覆盖掉。
- 快照同步：先对主节点的数据进行一次快照，传输到从节点，从节点根据快照进行全量加载，然后在进行增量同步，但是可能会出现，快照同步过程中，buffer中又出现了覆盖，然后又发起快照同步，进入死循环，因此需要有一个合理大小的buffer。

增加从节点：当从节点加入集群时，必须先进行快照同步，然后进行增量同步。主节点的快照同步操作是文件IO操作，因此对系统负载有较大影响，如果系统在进行AOF的fsync操作时有发送快照，fsync将会推迟，影响服务效率。因此支持无盘复制，主服务器直接通过套接字将快照内容发送到从节点，从节点将快照存储到磁盘，然后在进行一次性加载。

wait指令：同步复制。`wait 从库数量 时间(毫秒单位)`，将wait指令之前的写操作同步到N个从库中，最多等待时间t，如果为0，则无限等待，这是如果出现网络分区，会导致Redis服务器丧失可用性。

## 集群

### Sentinel

提供高可用方案来抵抗节点故障。客户点先访问sentinel获取最新的主节点地址，然后跟主节点进行交互，当主节点发生故障时，客户端会重新访问sentinel，获取最新的主节点。sentinel集群由多个节点组成，确保高可用，他负责监控主从节点的健康，当主节点挂掉后，自动选择最优的从节点切换为主节点。

Redis主从采用的是异步复制，因此当发送故障时，可能会出现未同步的消息丢失。Sentinel只能保证消息少丢失，可以通过两个选项限制主从延迟过大。

- `min-slavers-to-write 1`：主节点必须至少同一个从节点进行正常复制，否则停止对外写服务。
- `min-slaves-max-lag 10`：10秒未收到从节点反馈，则从节点同步不正常。

### Codis

单个Redis实例难以应对大数据高并发场景，主要体现在两点：

- 内存：当个Redis的内存不宜过大，内存过大会导致快照过大，从而导致主从同步时全量同步时间过长，重启实例也耗时过多。
- CPU利用率：单个Redis只能利用单个核心。

Codis是Redis集群解决方案，能将众多小内存的Redis实例综合起来，聚集多个机器上多个CPU核心的计算能力。客户端和Codis发送指令，Codis将指令发送给Redis实例来执行，然后返回结果。其是一个转发代理中间件。可以启动多个Codis服务，能提升QPS需求，并起到容灾功能。

分片原理：Codis将所有的key划分为1024个槽位，每个槽位都会唯一映射到一个实例，Codis在内存中唯一该映射关系。Codis会将客户端传递的key进行crc32获取哈希值，然后将结果对1024取余，获取槽位号，转发给相应的实例。

Codis实例之间如何同步槽位关系？

Codis使用ZooKeeper作为分布式配置存储数据库用于持久化槽位关系。

如何扩容？

当添加一个实例后，映射到该实例的槽位所对应的key都需要迁移到新的Redis实例中。Codis为Redis添加了SLOTSSCAN指令，用于遍历指定slot下所有key，然后将可以迁移到新的Redis中，当迁移过程中，接收到该槽位的新请求时，会将该key强制迁移，迁移完成后，在将请求发送对新的Redis实例中。

自动均衡：Codis提供自动均衡功能，会在系统比较空闲时观察每个Redis对应的Slots数量，当不平衡时，自动进行迁移。

Codis的代价？

不支持事务(只能在单个实例中完成)、不支持rename(两个key可能在不同的实例)、为了扩容时快速迁移，单个几个结构总字节量不要超过1M、网络开销比单个Redis大、需要zk，增加运维代价。

Codis优点？设计简单，将分布式问题交由第三方zk负责。

### Cluster

cluster是去中心化的，该集群由三个Redis节点组成，每个节点负责集群的一部分数据，三个节点相互连接组成一个对等集群，之间通过而是二进制协议交互集群信息。cluster将所有数据划分为16384的槽位，每个集群负责一部分槽位，槽位信息存储在节点中。

当客户端连接集群时，会获取一份集群槽位配置信息，因此客户端可以根据key直接定位到目标节点。

槽位定位算法：将key通过crc32计算一个hash值，然后与16384取模获得具体槽位号。当客户端向错误节点发送指令时，节点会判断指令的key所在的槽位，然后发送跳转指令要求客户端去链接相应节点(-MOVED 槽位号 节点IP)，客户端收到跳转信息后，更新槽位映射表(解决了槽位映射表的变化)

迁移：Redis的迁移单位是槽，当一个槽正在发送迁移时，该槽位进入中间过渡状态，原节点为migrating，目标节点为importing。迁移工具`redis-trib `会获取源节点中所有的key，然后挨个迁移，其流程是`源节点获取内容  =>  存到目标节点  =>  从源节点删除内容`，该过程是阻塞的，知道key被删除。迁移过程中，发送数据交互时，如客户端会尝试访问旧节点，如果数据在旧节点中，旧节点正常处理，如果不在旧节点中，返回`-ASK 目标节点IP`重定向指令，客户端收到后，会往目标节点执行一个不到参数的`asking`命令，然后重新执行指令(该槽位还未归新节点管理，因此直接下发命令，新节点会返回重定向指令，出现重定向循环，通过asking指令要求必须处理下一条指令)，这是一个指令需要3个ttl才能完成。

容错：cluster可以为每个主节点设置若干个从节点，单主节点故障时，自动选择一个从节点作为主节点，如果主节点没有从节点，则集群不可用。cluster-require-full-coverage 参数可以允许部分节点故障后，其他节点继续对外提供服务。

网络抖动：发送网络抖动后，会导致部分链接突然不可用，过一段时间后又恢复。可以设置`cluster-node-timeout`，当节点持续timeout时间失联后，才认定该节点出现故障，进行主从切换，如果没有则会导致主从频繁切换。`cluster-slave-validity-factor `参数可以作为倍乘系数，用于放大超时时间来宽容容错紧急程度，为0，则不抗网络抖动。

可能下线与确定下线？

Redis集群节点通过Gossip协议广播自己的状态和对集群的认知，当发现某个节点失联后，会进行集群广播，如果大多数节点都认为这个节点失联了，则会标记该节点为下线状态，整个集群广播，强迫其他节点接受该节点下线的事实，并进行主从切换。

槽位迁移感知

当Cluster发送槽位迁移后，客户端会将指令发送到原节点，这是节点发送`moved`告知客户端该槽位不归自己管，客户端更新槽位关系表，重试指令。如果该槽位处于迁移状态，指令会将指令发送到旧节点，如果数据不存在旧节点，则通过`asking error`告知客户端去新节点下发指令，客户端直接去新节点操作，不会刷新槽位映射关系表。重试可能会出现多次，因此要限制重试次数。

集群变更感知

服务器节点变更时，客户端应及时得到通知刷新自己的节点关系表。

- 目标节点挂了，客户端会出现`ConnectionError`，然后随机挑选一个节点重试，重试节点通过`moved error`告知目标槽位的新节点地址。
- 手动变更集群信息，将master切换到其他节点，移出集群，这是到旧节点的指令会受到`ClusterDown`的错误，告知节点所在集群不可用。客户端关闭所有连接，清空槽位映射表，向上层抛错，当新指令来临时，重试初始化节点信息。
