# kafka

## 是什么

`kafka`是由`Apache `开发的一款开源消息引擎系统，能在大数据场景中有效应对数据量激增、数据复杂度增加和数据变化速率变快等问题。

`kafka`最基本的功能是在不同的系统之间传递消息，其传递的消息格式为结构化消息的纯二进制字节序列。`kafka`支持两种消息传递方式：

- 点对点模型：系统A的信息只能被系统B接收。
- 发布/订阅模型：主题(消息容器)中有两个角色，发布者和订阅者，发布者负责往主题发送信息，订阅者能从主题中获取信息。

消息引擎系统有两大作用作用：

- 削峰填谷，其作用类似三峡大坝，能有效对抗上游的数据流量洪峰，使其变化更平滑，保护下游系统。
- 实现接收方与发送方松耦合(不用直接交互)。

源码阅读：先从`kafka.log`开始。

自上而下的学习，避免过早进入细节，学习了细节后，仍然不了解其组合起来的含义。

Kafka是消息引擎系统，也是分布式流处理平台。

Kafka设计特性：

- 提供API实现生产者和消费者。
- 降低网络传输和磁盘存储开销。
- 实现高伸缩架构。

在后续使用中，很多公司将其用于承接上下游、串联数据管道，因此在0.10.0.0版本后，变为分布式流处理平台。

优点：

- 更好的实现端到端的正确性，正确性是流处理能匹敌批处理的基石，正确性的基石是精确一次处理语义，很多大数据流处理框架只能实现在框架内的的精确一次处理语义，对框架之外无法影响。Kafka的数据流转和计算都在Kafka中完成，可以实现精确一次处理语义。
- 流式处理定位：面向中小型企业。

## 术语

- 消息(Record)：`Kafka`处理的对象。
- 主题(Topic)：消息容器，用于发布\订阅。
- 分区(Partitioning)：有序不变的消息序列。
- 消息位移(Offset)：分区中消费者消费到的位置。
- 生产者(Producer)：向主题发布消息的客户端。
- 消费者(Consumer)：订阅主题消息的客户端。
- 服务器端：由Broker服务进程构成，一个kafka集群由多个Broker组成，Broker复制接收、处理客户端发送的请求与消息的持久化。，Broker分散在不同机器上，实现高可用（一个节点挂掉、整个服务仍能提供）
- 副本(Replica)：将数据拷贝到多个节点，这些拷贝被称为副本，副本中有两种角色，Leader和Follower，Leader复制对外交互、Follower向Leader请求最新的数据，进行同步。
- 伸缩性：主题下划分分区，分区中存储有序的消息日志，消息只能被发送到一个分区中，分区编号从0开始，每个分区又有多个副本，消息在分区中的位置由分区位移表示(从0开始)。
- 消息日志：消息日志中分为多个日志段，生产者只能往日志中追加写(避免随机I/O，实现高吞吐量)，当日志段写满后，会新建日志段，然后分成老日志段，定期清理老日志段。
- 消费者位移：用于记录该消费者的消费进度。
- 消费者组：多个消费者组成一个组来消费一组主体，主题中每个分区只能被一个消费者消费，实现点对点。能同时消费多个分区，实现高吞吐。
- 重平衡机制：消费者组中，将挂掉的消费者负责的分区转交给其他消费者，通常会带来消费者问题，提供高可用。
- `Kafka`为什么不对外提供`Leader`副本读功能：
  - `kafka`中数据具备消费性质，读数据是对其进行消费，主从皆可读会涉及数据一致性问题，需要主从之间进行同步，会降低主从性能，`MySql`中数据是实体数据，不会涉及消费概念。
  - 提供主写从读的目的是为了减轻leader节点的压力，将读请求的负载均衡到follower节点上，如果将分区相对均匀的分配到每个broker，也能实现负载均衡(每次的只会访问一个分区)。
  - 主从读写分离适用于读多写少的场景，添加follower节点能有效提升。
  - kafka的副本机制使用的是异步消息拉取，存在leader和follower之间不一致问题。

## Kafka版本

- Apache Kafka：社区版Kafka，
  - 优点：迭代速度快，社区响应度高，把控度高。
  - 缺点：仅提供基础核心组件，缺乏高级特性。
  - 一句话点评：适用于高度定制化的场景。
- Confluent Kafka：Confluent公司提供
  - 优点：集成了很多高级特性，质量有保证。
  - 缺点：文档不全，缺乏范例，普及率不高。
  - 一句话点评：
- CDH|HDP Kafk：大数据云公司提供
  - 优点：集成了上下游，操作简单、维护方便
  - 缺点：把控度低，迭代速度慢。
  - 一句话点评：适合不想折腾，快速使用的用户。
- 版本号：Kafka-2.11-2.1.3
  - 2.11 指Scala编译器的版本
  - 2.1.3 代表Kafka的版本号，2表示大版本号，1代表小版本好，3代表修订版本号(Patch，补丁)
- 0.7 版本：只提供最基础的消息队列功能
- 0.8 版本：加入副本备份机制(实现了分布式高可靠消息队列)，开发客户端时只能使用老版API(需要传递zookeeper地址而非Broker地址)。0.8.2.0引入了新版本的Producer API，但是有bug,，老版API默认采用同步方式发送消息，吞吐量不高，0.8.2.2时，老版本API稳定。
- 0.9版本：添加了安全认证、权限功能，使用Java重写了新版本消费者API，引入了Kafka Connect组件用于实现高性能的数据抽取，新版本Producer API稳定，但Consumer API BUG满天飞。
- 0.10版本：引入了Kafka Streams，升级为分布式流处理平台，0.10.2.2 新版Consumer API稳定，并修复了可能导致Producer API性能的bug。
- 0.11版本：提供幂等性Producer API和事务API(正确性的基石)，对Kafka消息格式做了重构，0.11.0.3完善消息引擎功能。
- 1.0版本、2.0版本：主要是对Kafka Streams的改进，1.0和2.0很多不通用。
- 服务器端和客户端的版本号一致

